---
title: "Analyze data from Ostarek & Huettig (2017) and Lupyan & Ward (2013)"
author: '[Guillermo Montero-Melis](https://www.mpi.nl/people/montero-melis-guillermo)'
date: '`r as.character(format(Sys.Date(), format="%d/%m/%Y"))`'
output:
  html_document:
    depth: 2
    number_sections: yes
    theme: default
    toc: yes
---


Intro
====

Reanalysis of three datasets reporting a congruency effect in image detection
using CFS:

- Exp 1 in: Ostarek, M., & Huettig, F. (2017). Spoken words can make the
invisible visible—Testing the involvement of low-level visual representations in
spoken word processing. Journal of Experimental Psychology: Human Perception and
Performance, 43(3), 499–508. http://dx.doi.org/10.1037/xhp0000313 [*OH17*] 
- Exps 1 & 2 in: Lupyan, G., & Ward, E. J. (2013). Language can boost otherwise
unseen objects into visual awareness. Proceedings of the National Academy of
Sciences, 110(35), 14196–14201. https://doi.org/10.1073/pnas.1303312110
[*LW1* and *LW2*, respectively.]





Setup workspace
==============

Load libraries

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message=FALSE}
library("knitr")
library("tidyverse")  # ggplot2, dplyr, readr, purrr, etc
theme_set(theme_bw())
library("broom")
library("lme4")
library("lsr")  # cohensD function
```


Load original data sets:

```{r, message=FALSE}
# Load data OH17
ost <- read_csv("data_ostarek2017.csv") %>%
  mutate(participant = as.character(participant))
# For compatibility, "noPic" condition in OH17 --> "incongruent":
ost$condition[ost$condition == "noPic"] <- "incongruent"
head(ost) %>% kable
# L&W13
lw1 <- read_csv("data_lupyan13_exp1_simple.csv")
head(lw1) %>% kable
lw2 <- read_csv("data_lupyan13_exp2_simple.csv")
head(lw2) %>% kable
```

Combine into single data frame:

```{r}
# selection of columns:
cols_sel <- c("exp", "participant", "condition", "pic_presence", "prime",
              "target", "resp_acc", "RT")
comb <- bind_rows(
  ost %>% mutate(exp = "OH") %>% select(cols_sel),
  lw1 %>% mutate(exp = "LW1") %>% select(cols_sel),
  lw2 %>% mutate(exp = "LW2") %>% select(cols_sel)
)
# For plotting
comb$condition <- factor(
  comb$condition, levels = c("congruent", "noise", "incongruent")
  )
comb$exp <- factor(comb$exp, levels = c("OH", "LW1", "LW2"))
head(comb) %>% kable
```




Some basics for each study
============

Descriptives
-----------

Number of participants in each study:

```{r}
comb %>% 
  group_by(exp) %>% 
  summarise(N = length(unique(participant))) %>%
  kable
```


Number of target images in each study (excluding "no image"):

```{r}
comb %>% 
  filter(pic_presence == "present") %>%
  group_by(exp) %>% 
  summarise(N = length(unique(target))) %>%
  kable
```

Note that experiment LW2 had four versions for each of the 
`r length(unique(lw2$target)) - 1` target object categories.


Distribution of hit rates by participant in each experiment:

```{r}
comb %>%
  filter(pic_presence == "present") %>%
  group_by(exp, participant) %>%
  summarise(hit_rate = mean(resp_acc)) %>%
  group_by(exp) %>%
  summarise(
    min    = min(hit_rate),
    median = median(hit_rate),
    max    = max(hit_rate),
    mean   = mean(hit_rate),
    SD     = sd(hit_rate)
  ) %>%
  kable(digits = 2)
```

Distribution of false alarm (FA) rates by participant?

```{r}
comb %>%
  filter(pic_presence == "absent") %>%
  group_by(exp, participant) %>%
  summarise(FA_rate = 1 - mean(resp_acc)) %>%
  group_by(exp) %>%
  summarise(
    min    = min(FA_rate),
    median = median(FA_rate),
    max    = max(FA_rate),
    mean   = mean(FA_rate),
    SD     = sd(FA_rate)
  ) %>%
  kable(digits = 2)
```

The zero FA rates in LW2 will be problematic when computing $d'$ scores...




By-subject plots
===============

Accuracy
--------

```{r}
comb %>%
  group_by(exp, participant, condition, pic_presence) %>%
  summarise(accuracy = mean(resp_acc)) %>%
  ggplot(aes(x = condition, y = accuracy)) +
  stat_summary(fun.data = mean_cl_boot, colour = "red") +
  geom_jitter(height = 0, width = .2, alpha = .3) +
  facet_grid(pic_presence ~ exp) +
  ggtitle("Overall by-subject accuracy")
```


Reaction times
--------

```{r}
comb %>%
  group_by(exp, participant, condition, pic_presence) %>%
  summarise(RT = mean(RT)) %>%
  ggplot(aes(x = condition, y = RT)) +
  stat_summary(fun.data = mean_cl_boot, colour = "red") +
  geom_jitter(height = 0, width = .2, alpha = .3) +
  facet_grid(pic_presence ~ exp) +
  ggtitle("By-subject mean RTs")
```

Here the differences between experiments are quite striking. The long RTs in LW2
stand out. Let's look at OH17 and LW1, which are much more similar:

```{r}
comb %>%
  filter(exp != "LW2") %>%
  group_by(exp, participant, condition, pic_presence) %>%
  summarise(RT = mean(RT)) %>%
  ggplot(aes(x = condition, y = RT)) +
  stat_summary(fun.data = mean_cl_boot, colour = "red") +
  geom_jitter(height = 0, width = .2, alpha = .3) +
  facet_grid(pic_presence ~ exp) +
  ggtitle("By-subject mean RTs")
```



Analysis hit rates
==================

## Plots

```{r}
comb %>%
  filter(pic_presence == "present") %>%
  group_by(exp, participant, condition, pic_presence) %>%
  summarise(accuracy = mean(resp_acc)) %>%
  ggplot(aes(x = condition, y = accuracy)) +
  stat_summary(fun.data = mean_cl_boot, colour = "red", size = .75) +
  geom_jitter(height = 0, width = .2, alpha = .3) +
  facet_grid(. ~ exp) +
  ggtitle("Hit rates")
```


## Cell means by experiment

```{r}
by(comb, comb$exp, function(df) {
  df %>%
    filter(pic_presence == "present") %>%
    group_by(condition) %>%
    summarise(hit_rate = mean(resp_acc)) %>%
    kable(digits = 2)
})
```


## Repeated measures ANOVAs

By-subject:

```{r}
by(comb, comb$exp, function(df) {
  df <- df %>%
    filter(pic_presence == "present") %>%
    group_by(participant, condition, pic_presence) %>%
    summarise(accuracy = mean(resp_acc))
  aov <- aov(
    accuracy ~ condition + Error(participant / (condition)),
    data = df
  )
  summary(aov)
})
```



By-item:

```{r}
by(comb, comb$exp, function(df) {
  df <- df %>%
    filter(pic_presence == "present") %>%
    group_by(target, condition, pic_presence) %>%
    summarise(accuracy = mean(resp_acc))
  aov <- aov(
    accuracy ~ condition + Error(target / (condition)),
    data = df
  )
  summary(aov)
})
```

## GLMMs

We'll run a separate model for each data set, but first...

### Factor coding

```{r}
# Appropriate coding
# Convenience functions bc I might use them later in the script:
contrast2 <- function(v) {
  myfactor <- factor(v, levels = c("incongruent", "congruent"))
  contrasts(myfactor) <- contr.sum(2)
  colnames(contrasts(myfactor)) <- "incongr_congr"
  myfactor
  }
contrast3 <- function(v) {
  myfactor <- factor(v, levels = c("incongruent", "noise", "congruent"))
  contrasts(myfactor) <- contr.sum(3)
  colnames(contrasts(myfactor)) <- c("incongr_congr", "noise_congr")
  myfactor
  }

# LW1
lw1$condition_contr <- contrast3(lw1$condition)
contrasts(lw1$condition_contr)
# LW2
lw2$condition_contr <- contrast3(lw2$condition)
contrasts(lw2$condition_contr)
# OH17
ost$condition_contr <- contrast2(ost$condition)
contrasts(ost$condition_contr)
```

### OH17


```{r}
# # model fitting
# glmm_ost <- glmer(
#   resp_acc ~ condition_contr +
#     (1 + condition_contr | participant) +
#     (1 + condition_contr| target),
#   data = ost %>% filter(pic_presence == "present"),
#   family = "binomial"
# )
# # Save to disk
# write_rds(glmm_ost, "sims/glmm_ost.rds")
```

```{r}
glmm_ost <- read_rds("sims/glmm_ost.rds")
summary(glmm_ost)
```

Significant effect of congruency on hit rates.

### LW1

```{r}
# # model fitting
# # Adding by-item slope for condition leads to boundary singular fit, so simplify
# glmm_lw1 <- glmer(
#   resp_acc ~ condition_contr + (1 + condition_contr | participant) + (1 | target),
#   data = lw1 %>% filter(pic_presence == "present"),
#   family = "binomial"
# )
# # Save to disk
# write_rds(glmm_lw1, "sims/glmm_lw1.rds")
```


```{r}
glmm_lw1 <- read_rds("sims/glmm_lw1.rds")
summary(glmm_lw1)
```

Significant effect of congruency (incongruent vs congruent) on hit rates.

Let's compare this model against a null model by LRT:

```{r}
# # Null model
# glmm_lw1_null <- glmer(
#   resp_acc ~ 1 + (1 + condition_contr | participant) + (1 | target),
#   data = lw1 %>% filter(pic_presence == "present"),
#   family = "binomial"
# )
# # Save to disk
# write_rds(glmm_lw1_null, "sims/glmm_lw1_null.rds")
```


```{r}
glmm_lw1_null <- read_rds("sims/glmm_lw1_null.rds")
anova(glmm_lw1, glmm_lw1_null)
```

Confirms there is a main effect of the factor Condition.


### LW2

```{r}
# # model fitting
# # Adding by-item slope for condition leads to boundary singular fit, so simplify
# glmm_lw2 <- glmer(
#   resp_acc ~ condition_contr + (1 + condition_contr | participant) + (1 | target),
#   data = lw2 %>% filter(pic_presence == "present"),
#   family = "binomial"
# )
# # Save to disk
# write_rds(glmm_lw2, "sims/glmm_lw2.rds")
```


```{r}
glmm_lw2 <- read_rds("sims/glmm_lw2.rds")
summary(glmm_lw2)
```

Significant effect of congruency (incongruent vs congruent) on hit rates.

Let's again compare this model against a null model by LRT:

```{r}
# # Null model
# glmm_lw2_null <- glmer(
#   resp_acc ~ 1 + (1 + condition_contr | participant) + (1 | target),
#   data = lw2 %>% filter(pic_presence == "present"),
#   family = "binomial"
# )
# # Save to disk
# write_rds(glmm_lw2_null, "sims/glmm_lw2_null.rds")
```


```{r}
glmm_lw2_null <- read_rds("sims/glmm_lw2_null.rds")
anova(glmm_lw2, glmm_lw2_null)
```

Main effect of condition confirmed.



Analysis of sensitivity with d-prime
===================================

To build an understanding of $d'$ and $\beta$, see
[this interactive visualization](http://elvers.us/perception/sdtGraphic/)
and its associated
[SDT calculator](http://elvers.us/perception/sdtCalculator/).
For the computations, I'm following 
[this thread](https://psychology.stackexchange.com/questions/9282/calculating-d-prime).


## Compute $d'$

Compute $d'$ from false alarm and hit rates:

```{r}
# function to compute d'
dprime_fnc <- function(df) {
  FA <- df %>%
    filter(pic_presence == "absent") %>%
    group_by(exp, participant) %>%
    summarise(FA_rate = mean(1 - resp_acc)) %>%
    mutate(z_FA = qnorm(FA_rate))
  d_prime <- df %>%
    filter(pic_presence == "present") %>%
    group_by(exp, participant, condition) %>%
    summarise(H_rate = mean(resp_acc)) %>%
    mutate(z_H = qnorm(H_rate)) %>%
    left_join(FA) %>%
    mutate(d = z_H - z_FA)
  d_prime
}
# Compute
dprime_comb <- dprime_fnc(comb)
head(dprime_comb) %>% kable
```


## Sanity checks

Quite a few participants in LW2 yield non-finite values for $d'$ in some of the
conditions, either because their hit rate is 1, their false alarm rate is 0, or
both. This isn't reported for LW Exp2 (there is also mention of this for LW Exp
1, but these participants seem to have been removed from the data).

```{r}
inf_values <- apply(sapply(dprime_comb, is.infinite), 1, sum) != 0
dprime_comb[inf_values, ] %>%
  arrange(participant, condition)
```

How many non-finite values per condition?

```{r}
dprime_comb[inf_values, ] %>% group_by(condition) %>% count()
```


## Two ways of dealing with Infinite $d'$ scores

### Alternative 1: Exclusion

We exclude all non-finite observations:

```{r}
dprime_comb <- dprime_comb[! inf_values, ]
```


### Alternative 2: Change ceiling or floor observations

Jeroen suggested it is better to replace the floor and ceiling values by either
adding 1 false alarm (if FA rate = 0) or subtracting 1 hit (if Hit rate = 1).
This is what the following code snippet does.

```{r}
# TO DO
# See Stanislaw and Todorov (1999, p.143-144) "Hit and False-Alarm Rates of Zero
# or One" for different approaches. Jeroen essentially proposed the 4th approach
# but the authors seem to favour the 3rd approach ("loglinear")

# find_floor_ceiling_fnc <- function (df) {
#   FA_0 <- df %>%
#     filter(pic_presence == "absent") %>%
#     group_by(exp, participant, pic_presence) %>%
#     summarise(Acc = mean(resp_acc)) %>%
#     filter(Acc %in% c(1,0))
#   print(FA_0)
#   HR_1 <- df %>%
#     filter(pic_presence == "present") %>%
#     group_by(exp, participant, pic_presence, condition) %>%
#     summarise(Acc = mean(resp_acc)) %>%
#     filter(Acc %in% c(1,0))
#   print(HR_1)
# }
# find_floor_ceiling_fnc(comb)
```


## Plot $d'$ scores

```{r}
dprime_comb %>%
  ggplot(aes(x = condition, y = d)) +
  geom_line(aes(group = participant), alpha = .2) +
  stat_summary(fun.data = mean_cl_boot, colour = "red", size = .75) +
  geom_jitter(height = 0, width = .05, alpha = .3) +
  ylab("d' score") +
  facet_grid(. ~ exp)
```

For comparability, let's just plot the congruent vs incongruent conditions:

```{r}
dprime_comb %>%
  filter(condition != "noise") %>%
  ggplot(aes(x = condition, y = d)) +
  geom_line(aes(group = participant), alpha = .2) +
  stat_summary(fun.data = mean_cl_boot, colour = "red", size = .75) +
  geom_jitter(height = 0, width = .05, alpha = .3) +
  ylab("d' score") +
  facet_grid(. ~ exp)
```



## Cell means by experiment

```{r}
by(dprime_comb, dprime_comb$exp, function(df) {
  df %>%
    group_by(condition) %>%
    summarise(
      d_mean = mean(d),
      d_SD   = sd(d)
      ) %>%
    kable(digits = 2)
})
```


## t-test congruent vs incongruent

```{r}
# First exclude participants if one of the congr/incongr conditions is missing:
excl_ppt <- dprime_comb %>% 
  filter(condition != "noise") %>%
  group_by(participant) %>%
  count() %>%
  filter(n != 2) %>%
  pull(participant)
# t-test
dprime_comb %>%
  filter(
    participant != excl_ppt,
    condition %in% c("congruent", "incongruent")
    ) %>%
  mutate(condition = factor(condition)) %>%  # drop empty factor levels
  by(data = ., .$exp, function(df) {
    t.test(formula = d ~ condition, data = df, paired = TRUE)
  })
```


## Effect size: Cohen's $d$ for the congruency effect

```{r, warning = FALSE}
dprime_comb %>%
  filter(
    participant != excl_ppt,
    condition %in% c("congruent", "incongruent")
    ) %>%
  mutate(condition = factor(condition)) %>%  # drop empty factor levels
  by(data = ., .$exp, function(df) {
    cohensD(d ~ condition, data = df, method = "paired")
  })
```


## Linear models (LM) / Linear mixed models (LMM)

Our critical analysis of $d'$ scores is based on just two observations per
participant: one $d'$ sensitivity value for each of the two critical conditions.
With so few data points per participant it is not clear that fitting a LMM
makes much sense. Therefore we will fit both a LMM and a LM below and compare
the outcome. If there is no difference, we will use the simpler LMs in our power
simulations.


### Fit models

We'll use the [purrr approach](https://emoriebeck.github.io/R-tutorials/purrr/)
to model fitting.

```{r, warning = FALSE}
# Define functions
lm_d_fnc <- function(df) glm(d ~ 1 + condition_contr, data = df)
lmm_d_fnc <- function(df) {
  lmer(d ~ 1 + condition_contr + (1 | participant), data = df)
  }
# Fit models to data sets
dprime_comb_nested <- dprime_comb %>%
  # focus on critical conditions and implement contrast coding
  filter(condition %in% c("congruent", "incongruent")) %>%
  mutate(condition_contr = contrast2(condition)) %>%
  # nested structure
  group_by(exp) %>%
  nest() %>%
  # fit the models
  mutate(
    LM  = map(data, lm_d_fnc),
    LMM = map(data, lmm_d_fnc)
  ) %>%
  # extract model parameters with tidy
  mutate(
    LM_tidy  = map(LM, broom::tidy),
    LMM_tidy = map(LMM, broom::tidy)
  )
```

Get an idea of the data structure:

```{r}
dprime_comb_nested
# Check out column content
dprime_comb_nested %>% unnest(LM_tidy) %>% head(3) %>% kable
dprime_comb_nested %>% unnest(LMM_tidy) %>% head(5) %>% kable
```

Now combine into data frame that allows for comparison.

```{r}
dprime_compare_models <- bind_rows(
  dprime_comb_nested %>%
    unnest(LM_tidy) %>%
    select(exp : statistic) %>%
    mutate(model = "lm"),
  dprime_comb_nested %>%
    unnest(LMM_tidy) %>%
    filter(group == "fixed") %>%
    select(exp : statistic) %>%
    mutate(model = "lmm")
  ) %>%
  mutate(term = factor(term, labels = c("intercept", "beta"))) %>%
  arrange(exp, model, term)
dprime_compare_models %>% head %>% kable
```


### Plot comparison: LMM vs LM

```{r, fig.width = 8, fig.height = 4}
dprime_compare_models %>%
  ggplot(aes(x = term, y = estimate, colour = model)) +
  geom_hline(aes(yintercept = 0), linetype = "dashed") +
  geom_errorbar(
    aes(ymin = estimate - 2 * std.error,
        ymax = estimate + 2 * std.error),
    position = position_dodge(width=0.2),
    width = .1
    ) +
  facet_wrap(~ exp, scale = "free") +
  geom_point(size = 3, position = position_dodge(width=0.2)) +
 coord_flip()
```

While the estimates for the intercepts are almost identical, the estimate for
the critical coefficient is much reduced in the LMMs compared to the LMs.
This is probably because the latter are not capturing the within-subject
correlation inherent in a within-subjects design. Note also that the ANOVAs
above all yielded significant results for the critical coefficient. This is
because they captured the repeated measures by using the error terms.


### Results: LMMs on $d'$ scores

Here are the critical results, first as a figure:

```{r}
dprime_compare_models %>%
  filter(model == "lmm") %>%
  ggplot(aes(x = term, y = estimate)) +
  geom_hline(aes(yintercept = 0), linetype = "dashed") +
  geom_errorbar(
    aes(ymin = estimate - 2 * std.error,
        ymax = estimate + 2 * std.error),
    width = .1
    ) +
  facet_wrap(~ exp) +
  geom_point(size = 3)
```


Critical coefficients

```{r}
dprime_compare_models %>%
  filter(model == "lmm", term == "beta") %>%
  kable(digits = 2)
```

Note that the test statistics are very similar for the three data sets!


Finally, the complete model summaries:

```{r}
map(dprime_comb_nested$LMM, summary)
```



Analysis of reaction times
=======================

Descriptive plots
-----------------

Start by plotting the raw response times for correct trials in each study:

```{r}
comb %>%
  filter(resp_acc == 1) %>%
  ggplot(aes(x = condition, y = RT)) +
  geom_boxplot() +
  facet_grid(. ~ exp)
```

There are rather extreme observations in LW13 of >30 s! This makes me wonder if
analyzing the data using raw RTs (as in both studies) is the wisest way to go.

Let's look (again) at the by-subject reaction times, broken down by object 
presence:

```{r, fig.height=6, fig.width=7}
comb %>%
  filter(resp_acc == 1) %>%
  group_by(exp, participant, condition, pic_presence) %>%
  summarise(RT = mean(RT)) %>%
  ggplot(aes(x = condition, y = RT)) +
  geom_violin() +
  stat_summary(fun.data = mean_cl_boot, colour = "red", size = .25) +
  geom_jitter(height = 0, width = .2, alpha = .1) +
  facet_grid(pic_presence ~ exp) +
  ggtitle("By-subject mean RTs")
```

Averaged by subject RTs look more normal, which is probably good for the ANOVA
analysis performed in LW13.

The critical trials are those with hits. Plot those:


```{r}
# Raw RTs
comb %>%
  filter(pic_presence == "present", resp_acc == 1) %>%
  group_by(exp, participant, condition) %>%
  summarise(RT_mean = mean(RT)) %>%
  ggplot(aes(x = condition, y = RT_mean)) +
  geom_line(aes(group = participant), alpha = .2) +
  stat_summary(fun.data = mean_cl_boot, colour = "red", size = .75) +
  geom_jitter(height = 0, width = .05, alpha = .3) +
  facet_grid(. ~ exp) +
  ylab("Mean RT by subject") + 
  ggtitle("Raw RTs")
# Log RTs
comb %>%
  mutate(RT = log(RT)) %>%
  filter(pic_presence == "present", resp_acc == 1) %>%
  group_by(exp, participant, condition) %>%
  summarise(RT_mean = mean(RT)) %>%
  ggplot(aes(x = condition, y = RT_mean)) +
  geom_line(aes(group = participant), alpha = .2) +
  stat_summary(fun.data = mean_cl_boot, colour = "red", size = .75) +
  geom_jitter(height = 0, width = .05, alpha = .3) +
  facet_grid(. ~ exp) +
  ylab("Mean log(RT) by subject") + 
  ggtitle("Log RTs")
```


## Linear mixed models (LMM)

Analyze using LMMs, but restrict it to the two critical conditions (congruent
vs incongruent).

### Fit models

```{r, warning = FALSE}
# Define function
lmm_rt_fnc <- function(df, DV) {
  # model formula
  predictors <- c(
    "1", "condition_contr", "(1 | participant)", "(1 | target)"
    )
  f <- as.formula(paste(DV, paste(predictors, collapse = " + "), sep = " ~ "))
  # fit model
  lmer(formula = f, data = df)
  }
# Fit models to data sets
comb_lmm_RT <- comb %>%
  mutate(logRT = log(RT)) %>%
  filter(pic_presence == "present", resp_acc == 1) %>%
  # focus on critical conditions and implement contrast coding
  filter(condition %in% c("congruent", "incongruent")) %>%
  mutate(condition_contr = contrast2(condition)) %>%
  # nested structure
  group_by(exp) %>%
  nest() %>%
  # fit the models
  mutate(
    LMM_RT = map(data, lmm_rt_fnc, DV = "RT"),
    LMM_logRT = map(data, lmm_rt_fnc, DV = "logRT")
  ) %>%
  # extract model parameters with tidy
  mutate(
    LMM_RT_tidy    = map(LMM_RT, broom::tidy),
    LMM_logRT_tidy = map(LMM_logRT, broom::tidy),
)
```


```{r}
# Now combine into data frame that allows for comparison.
RT_models <- bind_rows(
  comb_lmm_RT %>%
    unnest(LMM_RT_tidy) %>%
    mutate(DV = "RT"),
  comb_lmm_RT %>%
    unnest(LMM_logRT_tidy) %>%
    mutate(DV = "logRT")
  ) %>%
  filter(group == "fixed") %>%
  select(exp : statistic, DV) %>%
  mutate(term = factor(term, labels = c("intercept", "beta"))) %>%
  arrange(exp, DV, term)
RT_models %>% kable
```


### Plot coefficients from LMMs with either RT or logRT as DV

```{r, fig.width = 8, fig.height = 4}
RT_models %>%
  filter(DV == "RT") %>%
  ggplot(aes(x = term, y = estimate)) +
  geom_hline(aes(yintercept = 0), linetype = "dashed") +
  geom_errorbar(
    aes(ymin = estimate - 2 * std.error,
        ymax = estimate + 2 * std.error),
    position = position_dodge(width=0.2),
    width = .1
    ) +
  facet_wrap(~ exp, scale = "free") +
  geom_point(size = 1, position = position_dodge(width=0.2)) +
  coord_flip() +
  ggtitle("Raw RTs")
```

```{r, fig.width = 8, fig.height = 4}
RT_models %>%
  filter(DV == "logRT") %>%
  ggplot(aes(x = term, y = estimate)) +
  geom_hline(aes(yintercept = 0), linetype = "dashed") +
  geom_errorbar(
    aes(ymin = estimate - 2 * std.error,
        ymax = estimate + 2 * std.error),
    position = position_dodge(width=0.2),
    width = .1
    ) +
  facet_wrap(~ exp, scale = "free") +
  geom_point(size = 1, position = position_dodge(width=0.2)) +
  coord_flip() +
  ggtitle("Log RTs")
```


### Model summaries

Critical coefficients

```{r}
RT_models %>% filter(term == "beta") %>% kable(digits = 2)
```

And the complete model summaries:

First with DV = raw RT
```{r}
map(comb_lmm_RT$LMM_RT, summary)
```

Then with DV = log(RT)

```{r}
map(comb_lmm_RT$LMM_logRT, summary)
```


### A closer look at RTs by participant

Individual data points grouped by participant and condition within experiment:

```{r}
plot_RT_fnc <- function(df, myexp) {
  # set up data frame
  df <- df %>% filter(exp == myexp, pic_presence == "present", resp_acc == 1)
  ppts_ordered <- df %>%
    group_by(participant) %>%
    summarise(
      RT_mean = mean(RT),
      RT_median = median(RT)
      ) %>%
    arrange(RT_mean) 
  df <- left_join(df, ppts_ordered)
  df$participant_ord <- factor(
    df$participant, levels = ppts_ordered %>% pull(participant)
    )
  # plot
  df %>%
    ggplot(aes(x = condition, y = RT)) +
    geom_boxplot() +
    facet_wrap(~ participant_ord) +
    geom_hline(aes(yintercept = RT_mean), linetype = "dotted", colour = "red") +
    geom_hline(aes(yintercept = RT_median), linetype = "dashed", colour = "blue") +
    ggtitle(paste(myexp, "- Raw RTs on hits"))
}
```

```{r, fig.height=7, fig.width=9}
plot_RT_fnc(comb, "OH")
plot_RT_fnc(comb, "LW1")
plot_RT_fnc(comb, "LW2")
```


Session info
===========

```{r}
sessionInfo()
```

