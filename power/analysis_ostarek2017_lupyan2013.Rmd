---
title: "Analyze data from Ostarek & Huetting (2017) and Lupyan & Ward (2013)"
author: '[Guillermo Montero-Melis](https://www.mpi.nl/people/montero-melis-guillermo)'
date: '`r as.character(format(Sys.Date(), format="%d/%m/%Y"))`'
output:
  html_document:
    depth: 2
    number_sections: yes
    theme: default
    toc: yes
---


Setup workspace
==============

Load libraries

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message=FALSE}
library("knitr")
library("tidyverse")  # ggplot2, dplyr, readr, purrr, etc
theme_set(theme_bw())
library("lme4")
library("lsr")
```


Load original data sets:

```{r, message=FALSE}
# Load data OH17
ost <- read_csv("data_ostarek2017.csv") %>%
  mutate(participant = as.character(participant))
# For compatibility, "noPic" condition in OH17 --> "incongruent":
ost$condition[ost$condition == "noPic"] <- "incongruent"
head(ost) %>% kable
# L&W13
lw1 <- read_csv("data_lupyan13_exp1_simple.csv")
head(lw1) %>% kable
lw2 <- read_csv("data_lupyan13_exp2_simple.csv")
head(lw2) %>% kable
```

Combine into single data frame:

```{r}
# selection of columns:
cols_sel <- c("exp", "participant", "condition", "pic_presence", "prime",
              "target", "resp_acc", "RT")
comb <- bind_rows(
  ost %>% mutate(exp = "OH") %>% select(cols_sel),
  lw1 %>% mutate(exp = "LW1") %>% select(cols_sel),
  lw2 %>% mutate(exp = "LW2") %>% select(cols_sel)
)
# For plotting
comb$condition <- factor(
  comb$condition, levels = c("congruent", "noise", "incongruent")
  )
comb$exp <- factor(comb$exp, levels = c("OH", "LW1", "LW2"))
head(comb) %>% kable
```




Some basics for each study
============

Number of participants in each study:

```{r}
comb %>% 
  group_by(exp) %>% 
  summarise(N = length(unique(participant))) %>%
  kable
```


Number of target images in each study (this includes the "absent image"):

```{r}
comb %>% 
  group_by(exp) %>% 
  summarise(N = length(unique(target))) %>%
  kable
```

Note that experiment LW2 had four versions for each of the 
`r length(unique(lw2$target)) - 1` target object categories.


Distribution of hit rates by participant in each experiment:

```{r}
comb %>%
  filter(pic_presence == "present") %>%
  group_by(exp, participant) %>%
  summarise(hit_rate = mean(resp_acc)) %>%
  group_by(exp) %>%
  summarise(
    min    = min(hit_rate),
    median = median(hit_rate),
    max    = max(hit_rate),
    mean   = mean(hit_rate),
    SD     = sd(hit_rate)
  ) %>%
  kable(digits = 2)
```

Distribution of false alarm (FA) rates by participant?

```{r}
comb %>%
  filter(pic_presence == "absent") %>%
  group_by(exp, participant) %>%
  summarise(FA_rate = 1 - mean(resp_acc)) %>%
  group_by(exp) %>%
  summarise(
    min    = min(FA_rate),
    median = median(FA_rate),
    max    = max(FA_rate),
    mean   = mean(FA_rate),
    SD     = sd(FA_rate)
  ) %>%
  kable(digits = 2)
```

The zero FA rates in LW2 will be problemati when computing d' scores...



By-subject plots
===============

Accuracy
--------

```{r}
comb %>%
  group_by(exp, participant, condition, pic_presence) %>%
  summarise(accuracy = mean(resp_acc)) %>%
  ggplot(aes(x = condition, y = accuracy)) +
  stat_summary(fun.data = mean_cl_boot, colour = "red") +
  geom_jitter(height = 0, width = .2, alpha = .3) +
  facet_grid(pic_presence ~ exp) +
  ggtitle("Overall by-subject accuracy")
```


Reaction times
--------

```{r}
comb %>%
  group_by(exp, participant, condition, pic_presence) %>%
  summarise(RT = mean(RT)) %>%
  ggplot(aes(x = condition, y = RT)) +
  stat_summary(fun.data = mean_cl_boot, colour = "red") +
  geom_jitter(height = 0, width = .2, alpha = .3) +
  facet_grid(pic_presence ~ exp) +
  ggtitle("By-subject mean RTs")
```

Here the differences between experiments are quite striking. The long RTs in LW2
stand out. Let's look at OH17 and LW1, which are much more similar:

```{r}
comb %>%
  filter(exp != "LW2") %>%
  group_by(exp, participant, condition, pic_presence) %>%
  summarise(RT = mean(RT)) %>%
  ggplot(aes(x = condition, y = RT)) +
  stat_summary(fun.data = mean_cl_boot, colour = "red") +
  geom_jitter(height = 0, width = .2, alpha = .3) +
  facet_grid(pic_presence ~ exp) +
  ggtitle("By-subject mean RTs")
```



Analysis hit rates
==================

## Plots

```{r}
comb %>%
  filter(pic_presence == "present") %>%
  group_by(exp, participant, condition, pic_presence) %>%
  summarise(accuracy = mean(resp_acc)) %>%
  ggplot(aes(x = condition, y = accuracy)) +
  stat_summary(fun.data = mean_cl_boot, colour = "red", size = .75) +
  geom_jitter(height = 0, width = .2, alpha = .3) +
  facet_grid(. ~ exp) +
  ggtitle("Hit rates")
```


## Cell means by experiment

```{r}
by(comb, comb$exp, function(df) {
  df %>%
    filter(pic_presence == "present") %>%
    group_by(condition) %>%
    summarise(hit_rate = mean(resp_acc)) %>%
    kable(digits = 2)
})
```


## Repeated measures ANOVAs

By-subject:

```{r}
by(comb, comb$exp, function(df) {
  df <- df %>%
    filter(pic_presence == "present") %>%
    group_by(participant, condition, pic_presence) %>%
    summarise(accuracy = mean(resp_acc))
  aov <- aov(
    accuracy ~ condition + Error(participant / (condition)),
    data = df
  )
  summary(aov)
})
```



By-item:

```{r}
by(comb, comb$exp, function(df) {
  df <- df %>%
    filter(pic_presence == "present") %>%
    group_by(target, condition, pic_presence) %>%
    summarise(accuracy = mean(resp_acc))
  aov <- aov(
    accuracy ~ condition + Error(target / (condition)),
    data = df
  )
  summary(aov)
})
```

## GLMMs

We'll run a separate model for each data set, but first adjust factor coding
scheme:

```{r}
# Appropriate coding:
# LW1
lw1$condition_contr <- factor(lw1$condition, levels = c("incongruent", "noise", "congruent"))
contrasts(lw1$condition_contr) <- contr.sum(3)
colnames(contrasts(lw1$condition_contr)) <- c("incongr_congr", "noise_congr")
contrasts(lw1$condition_contr)
# LW2
lw2$condition_contr <- factor(lw2$condition, levels = c("incongruent", "noise", "congruent"))
contrasts(lw2$condition_contr) <- contr.sum(3)
colnames(contrasts(lw2$condition_contr)) <- c("incongr_congr", "noise_congr")
contrasts(lw2$condition_contr)
# OH17
ost$condition_contr <- factor(ost$condition, levels = c("incongruent", "congruent"))
contrasts(ost$condition_contr) <- contr.sum(2)
colnames(contrasts(ost$condition_contr)) <- "incongr_congr"
contrasts(ost$condition_contr)
```

### OH17


```{r}
# # model fitting
# glmm_ost <- glmer(
#   resp_acc ~ condition_contr +
#     (1 + condition_contr | participant) +
#     (1 + condition_contr| prime),
#   data = ost %>% filter(pic_presence == "present"),
#   family = "binomial"
# )
# # Save to disk
# write_rds(glmm_ost, "sims/glmm_ost.rds")
```

```{r}
glmm_ost <- read_rds("sims/glmm_ost.rds")
summary(glmm_ost)
```


### LW1

```{r}
# # model fitting
# # Adding by-item slope for condition leads to boundary singular fit, so simplify
# glmm_lw1 <- glmer(
#   resp_acc ~ condition_contr + (1 + condition_contr | participant) + (1 | prime),
#   data = lw1 %>% filter(pic_presence == "present"),
#   family = "binomial"
# )
# # Save to disk
# write_rds(glmm_lw1, "sims/glmm_lw1.rds")
```


```{r}
glmm_lw1 <- read_rds("sims/glmm_lw1.rds")
summary(glmm_lw1)
```

There is no significant effect of congruency (incongruent vs congruent).

Let's compare this model against a null model by LRT:

```{r}
# # Null model
# glmm_lw1_null <- glmer(
#   resp_acc ~ 1 + (1 + condition_contr | participant) + (1 | prime),
#   data = lw1 %>% filter(pic_presence == "present"),
#   family = "binomial"
# )
# # Save to disk
# write_rds(glmm_lw1_null, "sims/glmm_lw1_null.rds")
```


```{r}
glmm_lw1_null <- read_rds("sims/glmm_lw1_null.rds")
anova(glmm_lw1, glmm_lw1_null)
```

Hmm, so there seems to be an effect of condition when comparing the two models
-- even though there is no signficant effect for the coefficient of interest!
How come?



### LW2

```{r}
# # model fitting
# # Adding by-item slope for condition leads to boundary singular fit, so simplify
# glmm_lw2 <- glmer(
#   resp_acc ~ condition_contr + (1 + condition_contr | participant) + (1 | prime),
#   data = lw2 %>% filter(pic_presence == "present"),
#   family = "binomial"
# )
# # Save to disk
# write_rds(glmm_lw2, "sims/glmm_lw2.rds")
```


```{r}
glmm_lw2 <- read_rds("sims/glmm_lw2.rds")
summary(glmm_lw2)
```

There is a marginal effect of congruency (incongruent vs congruent).

Let's again compare this model against a null model by LRT:

```{r}
# # Null model
# glmm_lw2_null <- glmer(
#   resp_acc ~ 1 + (1 + condition_contr | participant) + (1 | prime),
#   data = lw2 %>% filter(pic_presence == "present"),
#   family = "binomial"
# )
# # Save to disk
# write_rds(glmm_lw2_null, "sims/glmm_lw2_null.rds")
```


```{r}
glmm_lw2_null <- read_rds("sims/glmm_lw2_null.rds")
anova(glmm_lw2, glmm_lw2_null)
```

Once again, there is an effect of condition when comparing the two models with
LRT. How come?



Analysis of sensitivity with d-prime
===================================

To build an understanding of $d'$ and $\beta$, see
[this interactive visualization](http://elvers.us/perception/sdtGraphic/)
and its associated
[SDT calculator](http://elvers.us/perception/sdtCalculator/).
For the computations, I'm following 
[this thread](https://psychology.stackexchange.com/questions/9282/calculating-d-prime).


## Compute d'

Compute $d'$ from false alarm and hit rates:

```{r}
# function to compute d'
dprime_fnc <- function(df) {
  FA <- df %>%
    filter(pic_presence == "absent") %>%
    group_by(exp, participant) %>%
    summarise(FA_rate = mean(1 - resp_acc)) %>%
    mutate(z_FA = qnorm(FA_rate))
  d_prime <- df %>%
    filter(pic_presence == "present") %>%
    group_by(exp, participant, condition) %>%
    summarise(H_rate = mean(resp_acc)) %>%
    mutate(z_H = qnorm(H_rate)) %>%
    left_join(FA) %>%
    mutate(d = z_H - z_FA)
  d_prime
}
# Compute
dprime_comb <- dprime_fnc(comb)
head(dprime_comb) %>% kable
```


## Sanity checks

Quite a few participants in LW2 yield non-finite values for d' in some of the
conditions, either because their hit rate is 1, their false alarm rate is 0, or
both:

```{r}
inf_values <- apply(sapply(dprime_comb, is.infinite), 1, sum) != 0
dprime_comb[inf_values, ] %>%
  arrange(participant, condition)
```

How many non-finite values per condition?

```{r}
dprime_comb[inf_values, ] %>% group_by(condition) %>% count()
```


We exclude all non-finite observations:

```{r}
dprime_comb <- dprime_comb[! inf_values, ]
```


## Plot $d'$ scores

```{r}
dprime_comb %>%
  ggplot(aes(x = condition, y = d)) +
  geom_line(aes(group = participant), alpha = .2) +
  stat_summary(fun.data = mean_cl_boot, colour = "red", size = .75) +
  geom_jitter(height = 0, width = .05, alpha = .3) +
  ylab("d' score") +
  facet_grid(. ~ exp)
```

For comparability, let's just plot the congruent vs incongruent conditions:

```{r}
dprime_comb %>%
  filter(condition != "noise") %>%
  ggplot(aes(x = condition, y = d)) +
  geom_line(aes(group = participant), alpha = .2) +
  stat_summary(fun.data = mean_cl_boot, colour = "red", size = .75) +
  geom_jitter(height = 0, width = .05, alpha = .3) +
  ylab("d' score") +
  facet_grid(. ~ exp)
```



## Cell means by experiment

```{r}
by(dprime_comb, dprime_comb$exp, function(df) {
  df %>%
    group_by(condition) %>%
    summarise(
      d_mean = mean(d),
      d_SD   = sd(d)
      ) %>%
    kable(digits = 2)
})
```


## t-test congruent vs incongruent

```{r}
# First exclude participants if one of the congr/incongr conditions is missing:
excl_ppt <- dprime_comb %>% 
  filter(condition != "noise") %>%
  group_by(participant) %>%
  count() %>%
  filter(n != 2) %>%
  pull(participant)
# t-test
dprime_comb %>%
  filter(
    participant != excl_ppt,
    condition %in% c("congruent", "incongruent")
    ) %>%  
  by(data = ., .$exp, function(df) {
    t.test(formula = d ~ condition, data = df, paired = TRUE)
  })
```


## Mixed models


```{r}
# comb_nest <- dprime_comb %>%
#   nest(-exp) %>%
#   mutate(
#     model = map(data, function(df) {
#       lmer(d ~ 1 + condition + (1 | participant), data = df)
#       } 
#       )
#     )
# head(comb_nest)
```




Reaction times
==============


By-subject mean reaction times on trials with hits:

```{r}
ost %>%
  filter(pic_presence == "present", resp_acc == 1) %>%
  group_by(participant, condition) %>%
  summarise(RT_mean = mean(RT)) %>%
  ggplot(aes(x = condition, y = RT_mean)) +
  geom_line(aes(group = participant), alpha = .2) +
  stat_summary(fun.data = mean_cl_boot, colour = "red", size = .75) +
  geom_jitter(height = 0, width = .05, alpha = .3) +
  ylab("Mean RT by subject")
```

Individual data points grouped by participant:

```{r}
ppts_ordered <- ost %>% 
  filter(pic_presence == "present", resp_acc == 1) %>%
  group_by(participant) %>%
  summarise(
    RT_mean = mean(RT),
    RT_median = median(RT)
    ) %>%
  arrange(RT_mean) 
ost <- left_join(ost, ppts_ordered)
ost$participant_ord <- factor(ost$participant, levels = ppts_ordered %>% pull(participant))
```

```{r, fig.height = 10, fig.width = 8}
ost %>%
  filter(pic_presence == "present", resp_acc == 1) %>%
  ggplot(aes(x = condition, y = RT)) +
  geom_boxplot() +
  facet_wrap(~ participant_ord) +
  geom_hline(aes(yintercept = RT_mean), linetype = "dotted", colour = "red") +
  geom_hline(aes(yintercept = RT_median), linetype = "dashed", colour = "blue") +
  ggtitle("Raw Response Times (no outliers removed)")
```


