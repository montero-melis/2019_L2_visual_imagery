---
title: "Analyze data from Ostarek & Huetting (2017) and Lupyan & Ward (2013)"
author: '[Guillermo Montero-Melis](https://www.mpi.nl/people/montero-melis-guillermo)'
date: '`r as.character(format(Sys.Date(), format="%d/%m/%Y"))`'
output:
  html_document:
    depth: 2
    number_sections: yes
    theme: default
    toc: yes
---


Setup workspace
==============

Load libraries

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message=FALSE}
library("knitr")
library("tidyverse")  # ggplot2, dplyr, readr, purrr, etc
theme_set(theme_bw())
library("lme4")
library("lsr")
```


Load original data set:

```{r, message=FALSE}
# Load data OH17
ost <- read_csv("data_ostarek2017.csv")
head(ost) %>% kable
# LW13
lw1 <- read_csv("data_lupyan13_exp1_simple.csv")
lw1$condition <- factor(
  lw1$condition, levels = c("congruent", "noise", "incongruent")
  )
head(lw1) %>% kable
lw2 <- read_csv("data_lupyan13_exp2_simple.csv")
lw2$condition <- factor(
  lw2$condition, levels = c("congruent", "noise", "incongruent")
  )
head(lw2) %>% kable
```


Some basics for each study
============

Number of participants in each study:

```{r}
length(unique(ost$participant))
length(unique(lw1$participant))
length(unique(lw2$participant))
```

Five participants were excluded in OH17 (O&H17, p. 501). Are they still in the
data and are there extreme observations?

Hit rates by participant:

```{r}
ost %>%
  filter(pic_presence == "present") %>%
  group_by(participant) %>%
  summarise(hit_rate = mean(resp_acc)) %>%
  pull(hit_rate) %>%
  summary()

lw1 %>%
  filter(pic_presence == "present") %>%
  group_by(participant) %>%
  summarise(hit_rate = mean(resp_acc)) %>%
  pull(hit_rate) %>%
  summary()

lw2 %>%
  filter(pic_presence == "present") %>%
  group_by(participant) %>%
  summarise(hit_rate = mean(resp_acc)) %>%
  pull(hit_rate) %>%
  summary()
```


False alarm rates by participant?

```{r}
ost %>%
  filter(pic_presence == "absent") %>%
  group_by(participant) %>%
  summarise(FA_rate = mean(1 - resp_acc)) %>%
  pull(FA_rate) %>%
  summary()

lw1 %>%
  filter(pic_presence == "absent") %>%
  group_by(participant) %>%
  summarise(FA_rate = mean(1 - resp_acc)) %>%
  pull(FA_rate) %>%
  summary()

lw2 %>%
  filter(pic_presence == "absent") %>%
  group_by(participant) %>%
  summarise(FA_rate = mean(1 - resp_acc)) %>%
  pull(FA_rate) %>%
  summary()
```



Accuracy
=======

```{r}
ost %>%
  group_by(participant, condition) %>%
  summarise(accuracy = mean(resp_acc)) %>%
  ggplot(aes(x = condition, y = accuracy)) +
  stat_summary(fun.data = mean_cl_boot, colour = "red", size = 1) +
  geom_jitter(height = 0, width = .2, alpha = .3) +
  ggtitle("O&H17 Exp 1")
```

```{r}
lw1 %>%
  group_by(participant, condition, pic_presence) %>%
  summarise(accuracy = mean(resp_acc)) %>%
  ggplot(aes(x = condition, y = accuracy)) +
  stat_summary(fun.data = mean_cl_boot, colour = "red", size = 1) +
  geom_jitter(height = 0, width = .2, alpha = .3) +
  facet_grid(. ~ pic_presence) +
  ggtitle("L&W13 Exp 1")
```


```{r}
lw2 %>%
  group_by(participant, condition, pic_presence) %>%
  summarise(accuracy = mean(resp_acc)) %>%
  ggplot(aes(x = condition, y = accuracy)) +
  stat_summary(fun.data = mean_cl_boot, colour = "red", size = 1) +
  geom_jitter(height = 0, width = .2, alpha = .3) +
  facet_grid(. ~ pic_presence) +
  ggtitle("L&W13 Exp 2")
```



Reproduce analyses
==================


Hit rates
--------

### OH17

Figure 3:

```{r}
ost %>%
  filter(pic_presence == "present") %>%
  group_by(participant, condition) %>%
  summarise(hit_rate = mean(resp_acc)) %>%
  ggplot(aes(x = condition, y = hit_rate)) +
  stat_summary(fun.data = mean_cl_boot, colour = "red", size = 1) +
  geom_jitter(height = 0, width = .2, alpha = .3) +
  ggtitle("OH17 - Fig 3 (approx)")
```

```{r}
ost %>%
  filter(pic_presence == "present") %>%
  group_by(condition) %>%
  summarise(hit_rate = mean(resp_acc)) %>%
  kable(digits = 3)
```

The numbers are the same as in O&H17 up to the 2nd decimal (but small difference
in the 3rd).


### LW13 Exp 1

```{r}
lw1_sbj <- lw1 %>%
  filter(pic_presence == "present") %>%
  group_by(participant, condition, pic_presence) %>%
  summarise(accuracy = mean(resp_acc))
lw1_ite <- lw1 %>%
  filter(pic_presence == "present") %>%
  group_by(target, condition, pic_presence) %>%
  summarise(accuracy = mean(resp_acc))
```

#### Figure

```{r}
ggplot(lw1_sbj, aes(x = condition, y = accuracy)) +
  stat_summary(fun.data = mean_cl_boot, colour = "red", size = 1) +
  geom_jitter(height = 0, width = .2, alpha = .3) +
  ylab("Hit rates") +
  ggtitle("LW13 Exp 1")
```

Cell means:

```{r}
lw1 %>%
  filter(pic_presence == "present") %>%
  group_by(condition) %>%
  summarise(hit_rate = mean(resp_acc)) %>%
  kable(digits = 2)
```

Yes, these line up exactly with those reported in LW13.

#### Repeated measures ANOVAs

By-subject:

```{r}
aov_lw1_s <- aov(
  accuracy ~ condition + Error(participant / (condition)),
  data = lw1_sbj
  )
summary(aov_lw1_s)
```

Lines up with LW13!

By items:

```{r}
aov_lw1_i <- aov(
  accuracy ~ condition + Error(target / (condition)),
  data = lw1_ite
  )
summary(aov_lw1_i)
```


#### Does it come out with a GLMM?

```{r}
# Appropriate coding
lw1$condition_contr <- factor(lw1$condition, levels = c("incongruent", "noise", "congruent"))
contrasts(lw1$condition_contr) <- contr.sum(3)
colnames(contrasts(lw1$condition_contr)) <- c("incongr_congr", "noise_congr")
contrasts(lw1$condition_contr)
```


```{r}
# ## model fitting
# # Adding by-item slope for condition leads to boundary singular fit, so simplify
# glmm_lw1 <- glmer(
#   resp_acc ~ condition_contr + (1 + condition_contr | participant) + (1 | prime),
#   data = lw1 %>% filter(pic_presence == "present"),
#   family = "binomial"
# )
# # Save to disk
# write_rds(glmm_lw1, "sims/glmm_lw1.rds")
```


```{r}
glmm_lw1 <- read_rds("sims/glmm_lw1.rds")
summary(glmm_lw1)
```

It doesn't look like it does.

Let's compare this model against a null model by LRT:

```{r}
# # Null model
# glmm_lw1_null <- glmer(
#   resp_acc ~ 1 + (1 + condition_contr | participant) + (1 | prime),
#   data = lw1 %>% filter(pic_presence == "present"),
#   family = "binomial"
# )
# # Save to disk
# write_rds(glmm_lw1_null, "sims/glmm_lw1_null.rds")
```


```{r}
glmm_lw1_null <- read_rds("sims/glmm_lw1_null.rds")
anova(glmm_lw1, glmm_lw1_null)
```

Hmm, so there seems to be an effect of condition!

### LW13 Exp 2

```{r}
lw2 %>%
  filter(pic_presence == "present") %>%
  group_by(participant, condition) %>%
  summarise(hit_rate = mean(resp_acc)) %>%
  ggplot(aes(x = condition, y = hit_rate)) +
  stat_summary(fun.data = mean_cl_boot, colour = "red", size = 1) +
  geom_jitter(height = 0, width = .2, alpha = .3) +
  ggtitle("LW13 Exp 2")
```

```{r}
lw2 %>%
  filter(pic_presence == "present") %>%
  group_by(condition) %>%
  summarise(hit_rate = mean(resp_acc)) %>%
  kable(digits = 3)
```


d-prime
-------

To build an understanding of $d'$ and $\beta$, see
[this interactive visualization](http://elvers.us/perception/sdtGraphic/)
and its associated
[SDT calculator](http://elvers.us/perception/sdtCalculator/).
For the computations, I'm following 
[this thread](https://psychology.stackexchange.com/questions/9282/calculating-d-prime).

Compute $d'$ from false alarm and hit rates:

```{r}
dprime_fnc <- function(df) {
  FA <- df %>%
    filter(pic_presence == "absent") %>%
    group_by(participant) %>%
    summarise(FA_rate = mean(1 - resp_acc)) %>%
    mutate(z_FA = qnorm(FA_rate))
  d_prime <- df %>%
    filter(pic_presence == "present") %>%
    group_by(participant, condition) %>%
    summarise(H_rate = mean(resp_acc)) %>%
    mutate(z_H = qnorm(H_rate)) %>%
    left_join(FA) %>%
    mutate(d = z_H - z_FA)
  d_prime
}
```

```{r}
dprime_ost <- dprime_fnc(ost)
dprime_lw1 <- dprime_fnc(lw1)
dprime_lw2 <- dprime_fnc(lw2)
# Example with OH17 data
head(dprime_ost) %>% kable
```


### Figure 4

```{r}
dprime_ost %>%
  ggplot(aes(x = condition, y = d)) +
  geom_line(aes(group = participant), alpha = .2) +
  stat_summary(fun.data = mean_cl_boot, colour = "red", size = 1) +
  geom_jitter(height = 0, width = .05, alpha = .3) +
  ylab("d'-score") +
  ggtitle("Fig 4 (approx)")
```


### Cell means

```{r}
dprime_ost %>%
  group_by(condition) %>%
  summarise(M = mean(d), SD = sd(d)) %>%
  kable(digits = 3)
```


### t-test

```{r}
t.test(formula = d ~ condition, data = dprime_ost, paired = TRUE)
```


### Mixed model

```{r}
lmm_d <- lmer(d ~ 1 + condition + (1 | participant),
              data = dprime_ost)
summary(lmm_d)
```

Coincides with the results reported in the paper.


Reaction times
--------------

By-subject mean reaction times on trials with hits:

```{r}
ost %>%
  filter(pic_presence == "present", resp_acc == 1) %>%
  group_by(participant, condition) %>%
  summarise(RT_mean = mean(RT)) %>%
  ggplot(aes(x = condition, y = RT_mean)) +
  geom_line(aes(group = participant), alpha = .2) +
  stat_summary(fun.data = mean_cl_boot, colour = "red", size = 1) +
  geom_jitter(height = 0, width = .05, alpha = .3) +
  ylab("Mean RT by subject")
```

Individual data points grouped by participant:

```{r}
ppts_ordered <- ost %>% 
  filter(pic_presence == "present", resp_acc == 1) %>%
  group_by(participant) %>%
  summarise(
    RT_mean = mean(RT),
    RT_median = median(RT)
    ) %>%
  arrange(RT_mean) 
ost <- left_join(ost, ppts_ordered)
ost$participant_ord <- factor(ost$participant, levels = ppts_ordered %>% pull(participant))
```

```{r, fig.height = 10, fig.width = 8}
ost %>%
  filter(pic_presence == "present", resp_acc == 1) %>%
  ggplot(aes(x = condition, y = RT)) +
  geom_boxplot() +
  facet_wrap(~ participant_ord) +
  geom_hline(aes(yintercept = RT_mean), linetype = "dotted", colour = "red") +
  geom_hline(aes(yintercept = RT_median), linetype = "dashed", colour = "blue") +
  ggtitle("Raw Response Times (no outliers removed)")
```




Power analysis
==============

Cohen's *d*
-----------

```{r}
(cohens_d <- cohensD(d ~ condition, data = dprime_ost, method = "paired"))
```

Cohen's $d = `r round(cohens_d, 2)`$, somewhat bigger than a medium effect size.


BFDA: power to detect the effect in L1
--------------------------------------

Based on the data above, and in particular on the estimated Cohen's *d*,
I used the [interactive shiny bfda app](http://shinyapps.org/apps/BFDA/) to
generate a report that shows the sample size we would need to detect a language
effect (better detection in congruent vs incongruent condition).
The file name is `report_bfda_191030.pdf`.
Note that this report is estimating the probability of replicating the result
reported in O&H17!

The upshot of the report is:

- If the effect size is 0.6 and the *default prior* on effect size is used for
analyses, you will need **at least 62 observations per group** to obtain a 
*Bayes factor larger than 6* with a probability of p = 0.8.


```{r}
# # Run simulations and save to disk:
# 
# # Under alternative hypothesis H1 with ES d = 0.6
# sim_H1_d_06_defPrior <- BFDA.sim(
#   expected.ES = 0.6,
#   type = "t.paired",
#   prior=list("Cauchy",list(prior.location=0, prior.scale=sqrt(2)/2)),  # default non-informative
#   n.min=12, n.max=96, stepsize = 12, boundary=Inf,
#   alternative="two.sided",
#   B=1000, verbose=TRUE, cores=1)
# # Save to disk:
# write_rds(sim_H1_d_06_defPrior, "sims/sim_H1_d_06_defPrior.rds")
# 
# # Under null hypothesis H0
# sim_H0_defPrior <- BFDA.sim(
#   expected.ES = 0,  # under H0
#   type = "t.paired",
#   prior=list("Cauchy",list(prior.location=0, prior.scale=sqrt(2)/2)),  # default non-informative
#   n.min=12, n.max=96, stepsize = 12, boundary=Inf,
#   alternative="two.sided",
#   B=1000, verbose=TRUE, cores=1)
# # Save to disk:
# write_rds(sim_H0_defPrior, "sims/sim_H0_defPrior.rds")
```



